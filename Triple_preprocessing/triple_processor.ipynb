{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION - Edit this section for each processing task\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Get the base directory dynamically\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__ if '__file__' in globals() else '.')))\n",
    "TRIPLE_DIR = os.path.join(BASE_DIR, \"Triple_preprocessing\")\n",
    "\n",
    "processing_config = {\n",
    "    # Choose processing target\n",
    "    \"target\": \"RANDOM_150\",  # Options: RANDOM_150, ANNUAL_2023, ART7_2022, CAMBODIA_CMR_2023, CAMBODIA_MINES_2023, IWP_2023, IWP_2024\n",
    "    \n",
    "    # Processing settings\n",
    "    \"save_deleted_rows\": True,\n",
    "    \"save_empty_report\": True,\n",
    "    \"create_output_folder\": True\n",
    "}\n",
    "\n",
    "# Predefined target configurations\n",
    "target_configs = {\n",
    "    \"RANDOM_150\": {\n",
    "        \"input_csv\": os.path.join(TRIPLE_DIR, \"compute_metrics.csv\"),\n",
    "        \"output_folder\": TRIPLE_DIR,\n",
    "        \"output_prefix\": \"cleaned_output_random_150\",\n",
    "        \"columns_to_clean\": [\"mistral:instruct-7b\", \"vicuna-7b\", \"llama3-8b\", \"GPT-4o\", \"llama3-70b\"],\n",
    "        \"description\": \"Process random 150 sample data\"\n",
    "    },\n",
    "    \"ANNUAL_2023\": {\n",
    "        \"input_csv\": os.path.join(TRIPLE_DIR, \"All_triples_A1.csv\"),\n",
    "        \"output_folder\": os.path.join(TRIPLE_DIR, \"Annual_report_2023\"),\n",
    "        \"output_prefix\": \"cleaned_output\",\n",
    "        \"columns_to_clean\": [\"mistral-instruct\", \"vicuna\", \"llama3\", \"GPT-4o\", \"llama3-70b\"],\n",
    "        \"description\": \"Process Annual Report 2023 data\"\n",
    "    },\n",
    "    \"ART7_2022\": {\n",
    "        \"input_csv\": os.path.join(TRIPLE_DIR, \"All_triples_A1.csv\"),\n",
    "        \"output_folder\": os.path.join(TRIPLE_DIR, \"2023-Cambodia-Art7Report-for2022\"),\n",
    "        \"output_prefix\": \"cleaned_output\",\n",
    "        \"columns_to_clean\": [\"mistral-instruct\", \"vicuna\", \"llama3\", \"GPT-4o\", \"llama3-70b\"],\n",
    "        \"description\": \"Process Art7 Report 2022 data\"\n",
    "    },\n",
    "    \"CAMBODIA_CMR_2023\": {\n",
    "        \"input_csv\": os.path.join(TRIPLE_DIR, \"All_triples_A1.csv\"),\n",
    "        \"output_folder\": os.path.join(TRIPLE_DIR, \"CAMBODIA_CLEARING_CMR_2023\"),\n",
    "        \"output_prefix\": \"cleaned_output\",\n",
    "        \"columns_to_clean\": [\"mistral-instruct\", \"vicuna\", \"llama3\", \"GPT-4o\", \"llama3-70b\"],\n",
    "        \"description\": \"Process Cambodia CMR 2023 data\"\n",
    "    },\n",
    "    \"CAMBODIA_MINES_2023\": {\n",
    "        \"input_csv\": os.path.join(TRIPLE_DIR, \"All_triples_A1.csv\"),\n",
    "        \"output_folder\": os.path.join(TRIPLE_DIR, \"Cambodia_Clearing_the_Mines_2023\"),\n",
    "        \"output_prefix\": \"cleaned_output\",\n",
    "        \"columns_to_clean\": [\"mistral-instruct\", \"vicuna\", \"llama3\", \"GPT-4o\", \"llama3-70b\"],\n",
    "        \"description\": \"Process Cambodia Mines 2023 data\"\n",
    "    },\n",
    "    \"IWP_2023\": {\n",
    "        \"input_csv\": os.path.join(TRIPLE_DIR, \"All_triples_A1.csv\"),\n",
    "        \"output_folder\": os.path.join(TRIPLE_DIR, \"IWP-2023\"),\n",
    "        \"output_prefix\": \"cleaned_output\",\n",
    "        \"columns_to_clean\": [\"mistral-instruct\", \"vicuna\", \"llama3\", \"GPT-4o\", \"llama3-70b\"],\n",
    "        \"description\": \"Process IWP 2023 data\"\n",
    "    },\n",
    "    \"IWP_2024\": {\n",
    "        \"input_csv\": os.path.join(TRIPLE_DIR, \"All_triples_A1.csv\"),\n",
    "        \"output_folder\": os.path.join(TRIPLE_DIR, \"IWP-2024\"),\n",
    "        \"output_prefix\": \"cleaned_output\",\n",
    "        \"columns_to_clean\": [\"mistral-instruct\", \"vicuna\", \"llama3\", \"GPT-4o\", \"llama3-70b\"],\n",
    "        \"description\": \"Process IWP 2024 data\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Apply predefined config if specified\n",
    "if processing_config[\"target\"] in target_configs:\n",
    "    config = target_configs[processing_config[\"target\"]]\n",
    "    processing_config.update(config)\n",
    "\n",
    "print(f\"Target: {processing_config['target']}\")\n",
    "print(f\"Description: {processing_config.get('description', 'Custom processing')}\")\n",
    "print(f\"Input CSV: {processing_config.get('input_csv', 'Not specified')}\")\n",
    "print(f\"Output folder: {processing_config.get('output_folder', 'Not specified')}\")\n",
    "print(f\"Columns to clean: {processing_config.get('columns_to_clean', [])}\")\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Triple directory: {TRIPLE_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITY FUNCTIONS\n",
    "def extract_triples(text):\n",
    "    \"\"\"\n",
    "    Extract and clean triple format from text.\n",
    "    Removes indexing, filters valid triples, and cleans output prefixes.\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ''\n",
    "    \n",
    "    # Split the text into lines\n",
    "    lines = str(text).strip().split(\"\\n\")\n",
    "    \n",
    "    # Regex pattern to match triples with or without indexing\n",
    "    triple_pattern = re.compile(r'\\w+\\(.*\\)$')\n",
    "    \n",
    "    # Filter out lines that match the triple format and strip indexing if present\n",
    "    triples = [re.sub(r'^[^A-Za-z]*', '', line.strip()) for line in lines if triple_pattern.search(line.strip())]\n",
    "    \n",
    "    # Check if the first triple is prefixed with \"Output:\" or similar and remove it\n",
    "    if triples and triples[0].startswith(\"Output:\"):\n",
    "        triples[0] = re.sub(r'^Output:\\s*', '', triples[0])\n",
    "    \n",
    "    # Join the filtered triples back into a single string\n",
    "    return \"\\n\".join(triples)\n",
    "\n",
    "def create_output_paths(config):\n",
    "    \"\"\"\n",
    "    Create output file paths based on configuration.\n",
    "    \"\"\"\n",
    "    output_folder = config['output_folder']\n",
    "    output_prefix = config['output_prefix']\n",
    "    \n",
    "    # Create output folder if it doesn't exist\n",
    "    if config.get('create_output_folder', True):\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    paths = {\n",
    "        'cleaned_csv': os.path.join(output_folder, f\"{output_prefix}.csv\"),\n",
    "        'deleted_csv': os.path.join(output_folder, \"deleted_rows.csv\"),\n",
    "        'empty_report': os.path.join(output_folder, \"empty_cells_report.txt\")\n",
    "    }\n",
    "    \n",
    "    return paths\n",
    "\n",
    "def process_triples_data(config):\n",
    "    \"\"\"\n",
    "    Main processing function for triple data cleaning.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROCESSING: {config['target']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load CSV file\n",
    "    print(f\"Loading data from: {config['input_csv']}\")\n",
    "    df = pd.read_csv(config['input_csv'])\n",
    "    print(f\"Loaded {len(df)} rows\")\n",
    "    \n",
    "    # Get columns to clean\n",
    "    columns_to_clean = config['columns_to_clean']\n",
    "    print(f\"Processing columns: {columns_to_clean}\")\n",
    "    \n",
    "    # Verify columns exist in dataframe\n",
    "    missing_columns = [col for col in columns_to_clean if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"WARNING: Missing columns in data: {missing_columns}\")\n",
    "        columns_to_clean = [col for col in columns_to_clean if col in df.columns]\n",
    "        print(f\"Processing available columns: {columns_to_clean}\")\n",
    "    \n",
    "    # Apply the extraction function to each cell in the specified columns\n",
    "    print(\"Extracting and cleaning triples...\")\n",
    "    for column in columns_to_clean:\n",
    "        df[column] = df[column].apply(extract_triples)\n",
    "    \n",
    "    # Count empty cells after cleaning\n",
    "    empty_cells_count = {}\n",
    "    for column in columns_to_clean:\n",
    "        empty_cells_count[column] = (df[column] == '').sum()\n",
    "    \n",
    "    # Create output paths\n",
    "    paths = create_output_paths(config)\n",
    "    \n",
    "    # Save empty cells report\n",
    "    if config.get('save_empty_report', True):\n",
    "        with open(paths['empty_report'], 'w') as f:\n",
    "            for column, count in empty_cells_count.items():\n",
    "                line = f\"Column '{column}' has {count} empty cells after cleaning.\\n\"\n",
    "                f.write(line)\n",
    "                print(line.strip())\n",
    "        print(f\"Empty cells report saved to: {paths['empty_report']}\")\n",
    "    \n",
    "    # Identify and save rows to be deleted\n",
    "    if config.get('save_deleted_rows', True):\n",
    "        rows_to_delete = df[(df[columns_to_clean] == '').any(axis=1)]\n",
    "        rows_to_delete.to_csv(paths['deleted_csv'], index=False)\n",
    "        print(f\"Deleted {len(rows_to_delete)} rows with empty cells\")\n",
    "        print(f\"Deleted rows saved to: {paths['deleted_csv']}\")\n",
    "    \n",
    "    # Remove rows where any of the specified columns are empty after cleaning\n",
    "    df_cleaned = df[(df[columns_to_clean] != '').all(axis=1)]\n",
    "    \n",
    "    # Save the cleaned DataFrame\n",
    "    df_cleaned.to_csv(paths['cleaned_csv'], index=False)\n",
    "    print(f\"Cleaned data ({len(df_cleaned)} rows) saved to: {paths['cleaned_csv']}\")\n",
    "    \n",
    "    return df_cleaned, empty_cells_count\n",
    "\n",
    "print(\"Utility functions loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTE TRIPLE PROCESSING\n",
    "try:\n",
    "    # Run the processing\n",
    "    result_df, empty_counts = process_triples_data(processing_config)\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PROCESSING SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Target: {processing_config['target']}\")\n",
    "    print(f\"Final cleaned rows: {len(result_df)}\")\n",
    "    print(f\"Columns processed: {len(processing_config['columns_to_clean'])}\")\n",
    "    \n",
    "    print(f\"\\nEmpty cells by column:\")\n",
    "    for column, count in empty_counts.items():\n",
    "        print(f\"  {column}: {count} empty cells\")\n",
    "    \n",
    "    print(f\"\\nProcessing completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during processing: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}